{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from apex import amp\n",
    "import torch.cuda.amp as amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "cfg = {\n",
    "    'device_ids':0,\n",
    "    'batch_size':128,\n",
    "    'nz':100,\n",
    "    'nc':3,\n",
    "    'img_size':256,\n",
    "    'ngf':64,\n",
    "    'ndf':64,\n",
    "    'nepochs' : 100,# Number of training epochs.\n",
    "    'lr' : 0.0002,# Learning rate for optimizers\n",
    "    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer\n",
    "    'save_epoch' : 2,\n",
    "    'plot_loss_iter': 100,\n",
    "    'plot_img_iter': 1000}\n",
    "\n",
    "# create Generator \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.ConvTranspose2d(in_channels=cfg['nz'], out_channels=cfg['ngf'] * 32,\n",
    "                                         kernel_size=4, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg['ngf'] * 32)\n",
    "        self.layer2 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 32, out_channels=cfg['ngf'] * 16,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg['ngf'] * 16)\n",
    "        self.layer3 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 16, out_channels=cfg['ngf'] * 8,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(cfg['ngf'] * 8)\n",
    "        self.layer4 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 8, out_channels=cfg['ngf'] * 4,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(cfg['ngf'] * 4)\n",
    "        self.layer5 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 4, out_channels=cfg['ngf'] * 2,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(cfg['ngf'] * 2)\n",
    "        self.layer6 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 2, out_channels=3,\n",
    "                                         kernel_size=4, stride=2, padding=1) \n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.layer1(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn2(self.layer2(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn3(self.layer3(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn4(self.layer4(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn5(self.layer5(x)), 0.3, True)\n",
    "        x = torch.tanh(self.layer6(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels=cfg['nc'], out_channels=cfg['ndf'],\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg['ndf'])\n",
    "        self.layer2 = nn.Conv2d(in_channels=cfg['ndf'], out_channels=cfg['ndf'] * 2,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg['ndf'] * 2)\n",
    "        self.layer3 = nn.Conv2d(in_channels=cfg['ndf'] * 2, out_channels=cfg['ndf'] * 4,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(cfg['ndf'] * 4)\n",
    "        self.layer4 = nn.Conv2d(in_channels=cfg['ndf'] * 4, out_channels=cfg['ndf'] * 8,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(cfg['ndf'] * 8)\n",
    "        self.layer5 = nn.Conv2d(in_channels=cfg['ndf'] * 8, out_channels=cfg['ndf'] * 16,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(cfg['ndf'] * 16)\n",
    "        self.layer6 = nn.Conv2d(in_channels=cfg['ndf'] * 16, out_channels=1,\n",
    "                               kernel_size=4, stride=1, padding=0)\n",
    "       # self.bn6 = nn.BatchNorm2d(1)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x = F.leaky_relu(self.bn1(self.layer1(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn2(self.layer2(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn3(self.layer3(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn4(self.layer4(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn5(self.layer5(x)), 0.3, True)\n",
    "        x = self.layer6(x)\n",
    "        # x = torch.sigmoid(self.layer6(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(1, 100, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = g(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dateloadr \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "trms = transforms.Compose([  \n",
    "    transforms.CenterCrop((cfg['img_size'], cfg['img_size'])),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "real_data = ImageFolder(root='/home/scott/Desktop/dataset/face3k/', transform=trms)\n",
    "#real_data = ImageFolder(root='/Users/lionl771128/Desktop/data', transform=trms)\n",
    "real_dataloader = DataLoader(dataset=real_data, batch_size=cfg['batch_size'], shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "# from torchvision import transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "# import cv2\n",
    "# class FaceDataset(Dataset):\n",
    "#     def __init__(self, datapath, image_size=128, augment=False, cache_image=False):\n",
    "#         self.augment = augment\n",
    "#         self.image_size = image_size\n",
    "#         self.cache_image = cache_image\n",
    "#         self.trms = transforms.Compose([\n",
    "# #                                         transforms.CenterCrop([224, 224]),\n",
    "                                            \n",
    "# #                                         transforms.Resize([128, 128]),\n",
    "#                                         transforms.ToTensor(),\n",
    "#                                         transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "#                                                              std=[0.5, 0.5, 0.5])])\n",
    "#         # mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "#         with open(datapath, 'r') as f:\n",
    "#             self.image_path_list = f.readlines()\n",
    "\n",
    "#         if cache_image:\n",
    "#             self.image_list = []\n",
    "#             for img_path in self.image_path_list:\n",
    "#                 self.image_list.append(cv2.imread(img_path.strip()))\n",
    "\n",
    "#     def __cv2ToPillow(self, image):\n",
    "#         assert type(image) == np.ndarray, 'input should be a ndarray!'\n",
    "#         return Image.fromarray(image)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if self.cache_image:\n",
    "#             image = self.image_list[idx]\n",
    "#         else:\n",
    "#             image = cv2.imread(self.image_path_list[idx])\n",
    "        \n",
    "#         image = cv2.resize(image, (128, 128))\n",
    "#         # assert image.shape[:1] == (self.image_size, self.image_size), f'image size should be {self.image_size}'\n",
    "#         if self.augment:\n",
    "#             pass\n",
    "#         image = self.trms(image)\n",
    "#         label = torch.ones(1)\n",
    "#         return image, label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_path_list)\n",
    "    \n",
    "\n",
    "\n",
    "# data_path = '/home/scott/Desktop/dataset/face3k/train.txt'\n",
    "# real_data = FaceDataset(data_path, 128, cache_image=True)\n",
    "# #real_data = ImageFolder(root='/Users/lionl771128/Desktop/data', transform=trms)\n",
    "# real_dataloader = DataLoader(dataset=real_data, batch_size=cfg['batch_size'], shuffle=True, num_workers=8,\n",
    "#                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model, optimizier\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "device = 'cuda:' + str(cfg['device_ids']) if torch.cuda.is_available() else 'cpu'\n",
    "netG = Generator(cfg).to(device)\n",
    "netG.apply(weights_init)\n",
    "netD = Discriminator(cfg).to(device)\n",
    "netD.apply(weights_init)\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# training DCGAN by TTL\n",
    "optimizerG = Adam(netG.parameters(), lr=cfg['lr'], betas=[cfg['beta1'], 0.999])\n",
    "optimizerD = Adam(netD.parameters(), lr=cfg['lr']*3, betas=[cfg['beta1'], 0.999])\n",
    "lr_schedulerG = CosineAnnealingLR(optimizerG, T_max=100, eta_min=0)\n",
    "lr_schedulerD = CosineAnnealingLR(optimizerD, T_max=100, eta_min=0)\n",
    "\n",
    "# apex mix precision\n",
    "# amp.register_float_function(torch, 'sigmoid')\n",
    "# amp.register_float_function(torch, 'softmax')\n",
    "# model_list, optimizer_list = amp.initialize([netG, netD], [optimizerG, optimizerD], opt_level='O1', num_losses=3)\n",
    "\n",
    "# pytorh amp\n",
    "model_list = [netG, netD]\n",
    "optimizer_list = [optimizerG, optimizerD]\n",
    "\n",
    "netG = model_list[0]\n",
    "netD = model_list[1]\n",
    "optimizerG = optimizer_list[0]\n",
    "optimizerD = optimizer_list[1]\n",
    "#netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize loss & generated image\n",
    "# matplotlib繪圖基本教學: https://www.zhihu.com/question/51745620\n",
    "# matplotlib繪製動畫基本教學 https://blog.csdn.net/sailist/article/details/79475475\n",
    "'''\n",
    "matplotlib繪圖\n",
    "1.建立figure\n",
    "2.title命名\n",
    "3.傳入要繪圖的資料 plt.plot\n",
    "4.x,y軸命名\n",
    "5.選擇要畫的統計圖表類型(ex. legend)\n",
    "6.show\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(lossG_list, lossD_list):\n",
    "#     lossG_list = [1,2,3,4,5]\n",
    "#     lossD_list = [5,4,3,2,1]\n",
    "    loss_fig = plt.figure(figsize=(10, 5))\n",
    "    plt.title('Generator & Discriminator loss per iteration')\n",
    "    plt.plot(lossG_list, label='loss_G')\n",
    "    plt.plot(lossD_list, label='loss_D')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_record.jpg')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "matplotlib繪製動圖\n",
    "\n",
    "'''\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "def plot_generated_image(imgs, idx):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in imgs]\n",
    "    Writer = animation.writers['imagemagick']\n",
    "    writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "    anim = animation.ArtistAnimation(fig, ims, interval=1500, repeat_delay=1000, blit=True)\n",
    "    #plt.show()\n",
    "    anim.save(f'celeba_0-{idx}.gif', dpi=80, writer=writer)\n",
    "    #anim.save(f'celeba.gif', dpi=80, writer=writer)\n",
    "    \n",
    "'''\n",
    "將多張圖合併成一張大圖\n",
    "Pytorch torchvision.utils.make_grid()用法\n",
    "https://blog.csdn.net/u012343179/article/details/83007296\n",
    "'''\n",
    "\n",
    "import torchvision.utils as vutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# nvidia apex version\n",
    "# '''\n",
    "\n",
    "# # training \n",
    "# lossG_list = []\n",
    "# lossD_list = []\n",
    "# generated_imgs = []\n",
    "# num_epochs = cfg['nepochs']\n",
    "# iteration = 0\n",
    "# real_label = 1\n",
    "# fake_label = 0\n",
    "# fixed_noise = torch.randn(128, 100, 1, 1, device=device)\n",
    "# for epoch in range(num_epochs):\n",
    "#     with tqdm(real_dataloader, leave=False, total=len(real_dataloader)) as t:\n",
    "#         for idx, real_data in enumerate(t):\n",
    "#             # label = torch.full((cfg['batch_size'], ), real_label, device=device)\n",
    "#             real_data = real_data[0].to(device)\n",
    "#             #real_data.to(device)\n",
    "#            # print(real_data)\n",
    "#             '''\n",
    "#             train netD\n",
    "#             1. 將Discriminator梯度歸0\n",
    "#             2. 將real data傳入netD，計算loss(real label)和gradient\n",
    "#             3. 將雜訊z傳入netG生成fake data，並將fake data傳入netD，計算loss(fake label)和gradient(註)\n",
    "#             4. 更新參數\n",
    "#             (註)將fake data傳入netD時記得detach截斷這個node的gradient計算。以免計算梯度的時候將netG的節點計算進去。\n",
    "#             '''\n",
    "        \n",
    "#             #1\n",
    "#             netD.zero_grad()\n",
    "\n",
    "#             #2\n",
    "#             netD.train()\n",
    "#             out = netD(real_data).view(-1)\n",
    "#             real_label = torch.ones(out.shape[0]).to(device)\n",
    "#             #real_label = torch.ones(1).to(device)\n",
    "#            # print(out.shape)\n",
    "#             lossD_real = criterion(out, real_label)\n",
    "#             with amp.scale_loss(lossD_real, optimizerD, loss_id=0) as errD_real_scaled:\n",
    "#                 errD_real_scaled.backward()\n",
    "#             #lossD_real.backward()\n",
    "\n",
    "#             #3\n",
    "#             z = torch.randn(cfg['batch_size'], cfg['nz'], 1, 1, device=device)\n",
    "#             fake_data = netG(z)\n",
    "#             fake_label = torch.zeros(fake_data.shape[0]).to(device)\n",
    "#             #fake_label = torch.zeros(1).to(device)\n",
    "#             out = netD(fake_data.detach()).view(-1)\n",
    "#             lossD_fake = criterion(out, fake_label)\n",
    "#             with amp.scale_loss(lossD_fake, optimizerD, loss_id=1) as errD_fake_scaled:\n",
    "#                 errD_fake_scaled.backward()\n",
    "#             #lossD_fake.backward()\n",
    "\n",
    "#             #4\n",
    "#             optimizerD.step()\n",
    "#             lossD = lossD_fake + lossD_real\n",
    "#             lossD_list.append(lossD)\n",
    "                \n",
    "#             '''\n",
    "#             train netG\n",
    "#             1. 將Generator梯度歸0\n",
    "#             2. 將雜訊z傳入netG生成fake data，並將fake data傳入netD，計算loss(\"\"real label\"\")和gradient(註)\n",
    "#             3. 更新參數\n",
    "#             (註)將fake data傳入netD時不需要透過detach截斷這個node的gradient計算。或是關閉netD的gradient\n",
    "#                 因為即使計算gradient時會受D影響，但是optimizerG再刷新參數時並不會受到D的gradient影響。\n",
    "#                 計算圖流程:\n",
    "#                 z -> netG -> netD -> loss -> dloss/dD = dloss/dG * dG/dD\n",
    "#                 由上方的chain rule可得知，更新netG時用的gradient並不會受到netD影響\n",
    "#             '''\n",
    "\n",
    "#             # 1\n",
    "#             netG.zero_grad()\n",
    "\n",
    "#             # 2\n",
    "# #             z = torch.randn(cfg['batch_size'], cfg['nz'], 1, 1, device=device)\n",
    "# #             fake_data = netG(z)\n",
    "#             real_label = torch.ones(fake_data.shape[0]).to(device)\n",
    "#             out = netD(fake_data).view(-1)\n",
    "#             lossG = criterion(out, real_label)\n",
    "#             with amp.scale_loss(lossG, optimizerG, loss_id=2) as errG_scaled:\n",
    "#                 errG_scaled.backward()\n",
    "#             #print(lossG)\n",
    "#             #3\n",
    "#             optimizerG.step()\n",
    "\n",
    "#             lossG_list.append(lossG)\n",
    "\n",
    "#             #print(lossG_list)\n",
    "#            # print(lossD_list)\n",
    "#             if iteration % cfg['plot_loss_iter'] == 0:\n",
    "#                 plot_loss(lossG_list, lossD_list)\n",
    "#                 # plot_generated_image(generated_imgs)\n",
    "            \n",
    "#             if iteration % 100 == 0:\n",
    "#                 fake_imgs = netG(fixed_noise).detach().cpu()\n",
    "#                 generated_imgs.append(vutil.make_grid(fake_imgs, padding=2, normalize=True))\n",
    "                \n",
    "#             if iteration % cfg['plot_img_iter'] == 0:\n",
    "\n",
    "#                 with torch.no_grad():\n",
    "#                     fake_imgs = netG(fixed_noise).detach().cpu()\n",
    "#                 generated_imgs.append(vutil.make_grid(fake_imgs, padding=2, normalize=True))\n",
    "#                 plot_generated_image(generated_imgs, iteration)\n",
    "                \n",
    "#             iteration += 1\n",
    "#             lr_schedulerG.step()\n",
    "#             lr_schedulerD.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c194939ad7045ecaa7ddff06e376403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/.pyenv/versions/pytorch1.6_GAN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pytorch amp version\n",
    "'''\n",
    "\n",
    "# training \n",
    "lossG_list = []\n",
    "lossD_list = []\n",
    "generated_imgs = []\n",
    "num_epochs = cfg['nepochs']\n",
    "iteration = 0\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "fixed_noise = torch.randn(128, 100, 1, 1, device=device)\n",
    "\n",
    "# pytorch amp scaler\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(real_dataloader, leave=False, total=len(real_dataloader)) as t:\n",
    "        for idx, real_data in enumerate(t):\n",
    "            # label = torch.full((cfg['batch_size'], ), real_label, device=device)\n",
    "            real_data = real_data[0].to(device)\n",
    "            #real_data.to(device)\n",
    "           # print(real_data)\n",
    "            '''\n",
    "            train netD\n",
    "            1. 將Discriminator梯度歸0\n",
    "            2. 將real data傳入netD，計算loss(real label)和gradient\n",
    "            3. 將雜訊z傳入netG生成fake data，並將fake data傳入netD，計算loss(fake label)和gradient(註)\n",
    "            4. 更新參數\n",
    "            (註)將fake data傳入netD時記得detach截斷這個node的gradient計算。以免計算梯度的時候將netG的節點計算進去。\n",
    "            '''\n",
    "        \n",
    "            #1\n",
    "            netD.zero_grad()\n",
    "\n",
    "            #2\n",
    "            netD.train()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = netD(real_data).view(-1)\n",
    "                real_label = torch.ones(out.shape[0]).to(device)\n",
    "                lossD_real = criterion(out, real_label)\n",
    "            \n",
    "            scaler.scale(lossD_real).backward()\n",
    "            \n",
    "            #lossD_real.backward()\n",
    "\n",
    "            #3\n",
    "            z = torch.randn(cfg['batch_size'], cfg['nz'], 1, 1, device=device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                fake_data = netG(z)\n",
    "                fake_label = torch.zeros(fake_data.shape[0]).to(device)\n",
    "                #fake_label = torch.zeros(1).to(device)\n",
    "                out = netD(fake_data.detach()).view(-1)\n",
    "                lossD_fake = criterion(out, fake_label)\n",
    "            \n",
    "            scaler.scale(lossD_fake).backward()\n",
    "\n",
    "                \n",
    "        \n",
    "            #lossD_fake.backward()\n",
    "\n",
    "            #4\n",
    "            scaler.step(optimizerD)\n",
    "            lossD = lossD_fake + lossD_real\n",
    "            lossD_list.append(lossD)    \n",
    "            scaler.update()\n",
    "\n",
    "            '''\n",
    "            train netG\n",
    "            1. 將Generator梯度歸0\n",
    "            2. 將雜訊z傳入netG生成fake data，並將fake data傳入netD，計算loss(\"\"real label\"\")和gradient(註)\n",
    "            3. 更新參數\n",
    "            (註)將fake data傳入netD時不需要透過detach截斷這個node的gradient計算。或是關閉netD的gradient\n",
    "                因為即使計算gradient時會受D影響，但是optimizerG再刷新參數時並不會受到D的gradient影響。\n",
    "                計算圖流程:\n",
    "                z -> netG -> netD -> loss -> dloss/dD = dloss/dG * dG/dD\n",
    "                由上方的chain rule可得知，更新netG時用的gradient並不會受到netD影響\n",
    "            '''\n",
    "\n",
    "            # 1\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # 2\n",
    "#             z = torch.randn(cfg['batch_size'], cfg['nz'], 1, 1, device=device)\n",
    "#             fake_data = netG(z)\n",
    "            real_label = torch.ones(fake_data.shape[0]).to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = netD(fake_data).view(-1)\n",
    "                lossG = criterion(out, real_label)\n",
    "            \n",
    "            scaler.scale(lossG).backward()\n",
    "            #print(lossG)\n",
    "            #3\n",
    "            scaler.step(optimizerG)\n",
    "            scaler.update()\n",
    "\n",
    "            lossG_list.append(lossG)\n",
    "\n",
    "            #print(lossG_list)\n",
    "           # print(lossD_list)\n",
    "            if iteration % cfg['plot_loss_iter'] == 0:\n",
    "                plot_loss(lossG_list, lossD_list)\n",
    "                # plot_generated_image(generated_imgs)\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                fake_imgs = netG(fixed_noise).detach().cpu()\n",
    "                generated_imgs.append(vutil.make_grid(fake_imgs, padding=2, normalize=True))\n",
    "                \n",
    "            if iteration % cfg['plot_img_iter'] == 0:\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    fake_imgs = netG(fixed_noise).detach().cpu()\n",
    "                generated_imgs.append(vutil.make_grid(fake_imgs, padding=2, normalize=True))\n",
    "                plot_generated_image(generated_imgs, iteration)\n",
    "                \n",
    "            iteration += 1\n",
    "            lr_schedulerG.step()\n",
    "            lr_schedulerD.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
