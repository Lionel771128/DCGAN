{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "cfg = {\n",
    "    'device_ids':0,\n",
    "    'batch_size':128,\n",
    "    'nz':100,\n",
    "    'nc':3,\n",
    "    'img_size':128,\n",
    "    'ngf':64,\n",
    "    'ndf':64,\n",
    "    'nepochs' : 100,# Number of training epochs.\n",
    "    'lr' : 0.0002,# Learning rate for optimizers\n",
    "    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer\n",
    "    'save_epoch' : 2,\n",
    "    'plot_loss_iter': 100,\n",
    "    'plot_img_iter': 1000}\n",
    "\n",
    "# create Generator \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.ConvTranspose2d(in_channels=cfg['nz'], out_channels=cfg['ngf'] * 32,\n",
    "                                         kernel_size=4, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg['ngf'] * 32)\n",
    "        self.layer2 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 32, out_channels=cfg['ngf'] * 16,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg['ngf'] * 16)\n",
    "        self.layer3 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 16, out_channels=cfg['ngf'] * 8,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(cfg['ngf'] * 8)\n",
    "        self.layer4 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 8, out_channels=cfg['ngf'] * 4,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(cfg['ngf'] * 4)\n",
    "        self.layer5 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 4, out_channels=cfg['ngf'] * 2,\n",
    "                                         kernel_size=4, stride=2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(cfg['ngf'] * 2)\n",
    "        self.layer6 = nn.ConvTranspose2d(in_channels=cfg['ngf'] * 2, out_channels=3,\n",
    "                                         kernel_size=4, stride=2, padding=1) \n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.layer1(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn2(self.layer2(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn3(self.layer3(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn4(self.layer4(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn5(self.layer5(x)), 0.3, True)\n",
    "        x = torch.tanh(self.layer6(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels=cfg['nc'], out_channels=cfg['ndf'],\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg['ndf'])\n",
    "        self.layer2 = nn.Conv2d(in_channels=cfg['ndf'], out_channels=cfg['ndf'] * 2,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg['ndf'] * 2)\n",
    "        self.layer3 = nn.Conv2d(in_channels=cfg['ndf'] * 2, out_channels=cfg['ndf'] * 4,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(cfg['ndf'] * 4)\n",
    "        self.layer4 = nn.Conv2d(in_channels=cfg['ndf'] * 4, out_channels=cfg['ndf'] * 8,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(cfg['ndf'] * 8)\n",
    "        self.layer5 = nn.Conv2d(in_channels=cfg['ndf'] * 8, out_channels=cfg['ndf'] * 16,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(cfg['ndf'] * 16)\n",
    "        self.layer6 = nn.Conv2d(in_channels=cfg['ndf'] * 16, out_channels=1,\n",
    "                               kernel_size=4, stride=1, padding=0)\n",
    "       # self.bn6 = nn.BatchNorm2d(1)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x = F.leaky_relu(self.bn1(self.layer1(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn2(self.layer2(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn3(self.layer3(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn4(self.layer4(x)), 0.3, True)\n",
    "        x = F.leaky_relu(self.bn5(self.layer5(x)), 0.3, True)\n",
    "        x = self.layer6(x)\n",
    "        # x = torch.sigmoid(self.layer6(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(1, 100, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = g(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dateloadr \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "trms = transforms.Compose([  \n",
    "    transforms.CenterCrop((cfg['img_size'], cfg['img_size'])),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "real_data = ImageFolder(root='C:/Users/scott/dataset/img_align_celeba', transform=trms)\n",
    "#real_data = ImageFolder(root='/Users/lionl771128/Desktop/data', transform=trms)\n",
    "real_dataloader = DataLoader(dataset=real_data, batch_size=cfg['batch_size'], shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"
     ]
    }
   ],
   "source": [
    "# create model, optimizier\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "device = 'cuda:' + str(cfg['device_ids']) if torch.cuda.is_available() else 'cpu'\n",
    "netG = Generator(cfg).to(device)\n",
    "netG.apply(weights_init)\n",
    "netD = Discriminator(cfg).to(device)\n",
    "netD.apply(weights_init)\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# training DCGAN by TTL\n",
    "optimizerG = Adam(netG.parameters(), lr=cfg['lr'], betas=[cfg['beta1'], 0.999])\n",
    "optimizerD = Adam(netD.parameters(), lr=cfg['lr']*3, betas=[cfg['beta1'], 0.999])\n",
    "lr_schedulerG = CosineAnnealingLR(optimizerG, T_max=100, eta_min=0)\n",
    "lr_schedulerD = CosineAnnealingLR(optimizerD, T_max=100, eta_min=0)\n",
    "\n",
    "# apex mix precision\n",
    "amp.register_float_function(torch, 'sigmoid')\n",
    "amp.register_float_function(torch, 'softmax')\n",
    "model_list, optimizer_list = amp.initialize([netG, netD], [optimizerG, optimizerD], opt_level='O1', num_losses=3)\n",
    "netG = model_list[0]\n",
    "netD = model_list[1]\n",
    "optimizerG = optimizer_list[0]\n",
    "optimizerD = optimizer_list[1]\n",
    "#netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize loss & generated image\n",
    "# matplotlib繪圖基本教學: https://www.zhihu.com/question/51745620\n",
    "# matplotlib繪製動畫基本教學 https://blog.csdn.net/sailist/article/details/79475475\n",
    "'''\n",
    "matplotlib繪圖\n",
    "1.建立figure\n",
    "2.title命名\n",
    "3.傳入要繪圖的資料 plt.plot\n",
    "4.x,y軸命名\n",
    "5.選擇要畫的統計圖表類型(ex. legend)\n",
    "6.show\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(lossG_list, lossD_list):\n",
    "#     lossG_list = [1,2,3,4,5]\n",
    "#     lossD_list = [5,4,3,2,1]\n",
    "    loss_fig = plt.figure(figsize=(10, 5))\n",
    "    plt.title('Generator & Discriminator loss per iteration')\n",
    "    plt.plot(lossG_list, label='loss_G')\n",
    "    plt.plot(lossD_list, label='loss_D')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_record.jpg')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "matplotlib繪製動圖\n",
    "\n",
    "'''\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "def plot_generated_image(imgs, idx):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in imgs]\n",
    "    Writer = animation.writers['imagemagick']\n",
    "    writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "    anim = animation.ArtistAnimation(fig, ims, interval=1500, repeat_delay=1000, blit=True)\n",
    "    #plt.show()\n",
    "    anim.save(f'celeba_0-{idx}.gif', dpi=80, writer=writer)\n",
    "    #anim.save(f'celeba.gif', dpi=80, writer=writer)\n",
    "    \n",
    "'''\n",
    "將多張圖合併成一張大圖\n",
    "Pytorch torchvision.utils.make_grid()用法\n",
    "https://blog.csdn.net/u012343179/article/details/83007296\n",
    "'''\n",
    "\n",
    "import torchvision.utils as vutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:91: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 4096.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 16384.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 16384.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0b4ca05d8b40fc8cc011269c30e3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1583.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 2 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-ddb9d1135a33>\", line 88, in <module>\n",
      "    plot_loss(lossG_list, lossD_list)\n",
      "  File \"<ipython-input-12-95a737bffe0e>\", line 20, in plot_loss\n",
      "    plt.plot(lossD_list, label='loss_D')\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py\", line 2763, in plot\n",
      "    is not None else {}), **kwargs)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_axes.py\", line 1649, in plot\n",
      "    self.add_line(line)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 1850, in add_line\n",
      "    self._update_line_limits(line)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 1872, in _update_line_limits\n",
      "    path = line.get_path()\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\lines.py\", line 1027, in get_path\n",
      "    self.recache()\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\lines.py\", line 675, in recache\n",
      "    y = _to_unmasked_float_array(yconv).ravel()\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\", line 1317, in _to_unmasked_float_array\n",
      "    return np.asarray(x, float)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000017D80C89378> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     37\u001b[0m             display(\n\u001b[0;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             )\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\scott\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2098\u001b[0m                            else suppress())\n\u001b[0;32m   2099\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2100\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bbox_extra_artists\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1736\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2630\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[1;32m--> 626\u001b[1;33m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mmake_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             magnification, unsampled=unsampled)\n\u001b[0m\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scalar_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m                 output_alpha = _resample(  # resample alpha channel\n\u001b[1;32m--> 522\u001b[1;33m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[0m\u001b[0;32m    523\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[0;32m    524\u001b[0m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_resample\u001b[1;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[0;32m    200\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mimage_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_filternorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m                     image_obj.get_filterrad())\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training \n",
    "lossG_list = []\n",
    "lossD_list = []\n",
    "generated_imgs = []\n",
    "num_epochs = cfg['nepochs']\n",
    "iteration = 0\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "fixed_noise = torch.randn(128, 100, 1, 1, device=device)\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(real_dataloader, leave=False, total=len(real_dataloader)) as t:\n",
    "        for idx, real_data in enumerate(t):\n",
    "            # label = torch.full((cfg['batch_size'], ), real_label, device=device)\n",
    "            real_data = real_data[0].to(device)\n",
    "            #real_data.to(device)\n",
    "           # print(real_data)\n",
    "            '''\n",
    "            train netD\n",
    "            1. 將Discriminator梯度歸0\n",
    "            2. 將real data傳入netD，計算loss(real label)和gradient\n",
    "            3. 將雜訊z傳入netG生成fake data，並將fake data傳入netD，計算loss(fake label)和gradient(註)\n",
    "            4. 更新參數\n",
    "            (註)將fake data傳入netD時記得detach截斷這個node的gradient計算。以免計算梯度的時候將netG的節點計算進去。\n",
    "            '''\n",
    "        \n",
    "            #1\n",
    "            netD.zero_grad()\n",
    "\n",
    "            #2\n",
    "            netD.train()\n",
    "            out = netD(real_data).view(-1)\n",
    "            real_label = torch.ones(out.shape[0]).to(device)\n",
    "            #real_label = torch.ones(1).to(device)\n",
    "           # print(out.shape)\n",
    "            lossD_real = criterion(out, real_label)\n",
    "            with amp.scale_loss(lossD_real, optimizerD, loss_id=0) as errD_real_scaled:\n",
    "                errD_real_scaled.backward()\n",
    "            #lossD_real.backward()\n",
    "\n",
    "            #3\n",
    "            z = torch.randn(cfg['batch_size'], cfg['nz'], 1, 1, device=device)\n",
    "            fake_data = netG(z)\n",
    "            fake_label = torch.zeros(fake_data.shape[0]).to(device)\n",
    "            #fake_label = torch.zeros(1).to(device)\n",
    "            out = netD(fake_data.detach()).view(-1)\n",
    "            lossD_fake = criterion(out, fake_label)\n",
    "            with amp.scale_loss(lossD_fake, optimizerD, loss_id=1) as errD_fake_scaled:\n",
    "                errD_fake_scaled.backward()\n",
    "            #lossD_fake.backward()\n",
    "\n",
    "            #4\n",
    "            optimizerD.step()\n",
    "            lossD = lossD_fake + lossD_real\n",
    "            lossD_list.append(lossD)\n",
    "                \n",
    "            '''\n",
    "            train netG\n",
    "            1. 將Generator梯度歸0\n",
    "            2. 將雜訊z傳入netG生成fake data，並將fake data傳入netD，計算loss(\"\"real label\"\")和gradient(註)\n",
    "            3. 更新參數\n",
    "            (註)將fake data傳入netD時不需要透過detach截斷這個node的gradient計算。或是關閉netD的gradient\n",
    "                因為即使計算gradient時會受D影響，但是optimizerG再刷新參數時並不會受到D的gradient影響。\n",
    "                計算圖流程:\n",
    "                z -> netG -> netD -> loss -> dloss/dD = dloss/dG * dG/dD\n",
    "                由上方的chain rule可得知，更新netG時用的gradient並不會受到netD影響\n",
    "            '''\n",
    "\n",
    "            # 1\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # 2\n",
    "#             z = torch.randn(cfg['batch_size'], cfg['nz'], 1, 1, device=device)\n",
    "#             fake_data = netG(z)\n",
    "            real_label = torch.ones(fake_data.shape[0]).to(device)\n",
    "            out = netD(fake_data).view(-1)\n",
    "            lossG = criterion(out, real_label)\n",
    "            with amp.scale_loss(lossG, optimizerG, loss_id=2) as errG_scaled:\n",
    "                errG_scaled.backward()\n",
    "            #print(lossG)\n",
    "            #3\n",
    "            optimizerG.step()\n",
    "\n",
    "            lossG_list.append(lossG)\n",
    "\n",
    "            #print(lossG_list)\n",
    "           # print(lossD_list)\n",
    "            if iteration % cfg['plot_loss_iter'] == 0:\n",
    "                plot_loss(lossG_list, lossD_list)\n",
    "                # plot_generated_image(generated_imgs)\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                fake_imgs = netG(fixed_noise).detach().cpu()\n",
    "                generated_imgs.append(vutil.make_grid(fake_imgs, padding=2, normalize=True))\n",
    "                \n",
    "            if iteration % cfg['plot_img_iter'] == 0:\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    fake_imgs = netG(fixed_noise).detach().cpu()\n",
    "                generated_imgs.append(vutil.make_grid(fake_imgs, padding=2, normalize=True))\n",
    "                plot_generated_image(generated_imgs, iteration)\n",
    "                \n",
    "            iteration += 1\n",
    "            lr_schedulerG.step()\n",
    "            lr_schedulerD.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
